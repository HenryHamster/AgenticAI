{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Green Agent Evaluation Consistency Test\n",
        "\n",
        "This notebook tests whether the green agent's evaluation produces consistent results when provided with the same answers/inputs across different instances.\n",
        "\n",
        "**Test Setup:**\n",
        "- Runs 60 evaluations with identical inputs\n",
        "- Uses fixed mock responses for player actions\n",
        "- Compares results for consistency (winner, final wealth, final health, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded environment variables from /Users/cyro/Documents/VSC/AgenticAI/backend/.env\n",
            "‚úì OPENAI_API_KEY found (length: 164)\n",
            "Imports successful!\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "from typing import Dict, Any, List\n",
        "from collections import Counter\n",
        "import statistics\n",
        "import types\n",
        "from datetime import datetime, timedelta\n",
        "from dotenv import load_dotenv\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Add backend to path\n",
        "backend_path = os.path.join(os.path.dirname(os.getcwd()), 'backend')\n",
        "if os.path.exists(backend_path):\n",
        "    sys.path.insert(0, backend_path)\n",
        "else:\n",
        "    # Try current directory\n",
        "    backend_path = os.path.join(os.getcwd(), 'backend')\n",
        "    if os.path.exists(backend_path):\n",
        "        sys.path.insert(0, backend_path)\n",
        "\n",
        "# Load environment variables from backend/.env BEFORE importing anything that uses them\n",
        "env_path = os.path.join(backend_path, '.env')\n",
        "if os.path.exists(env_path):\n",
        "    load_dotenv(env_path, override=True)\n",
        "    print(f\"Loaded environment variables from {env_path}\")\n",
        "    # Verify API key is loaded\n",
        "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if api_key:\n",
        "        print(f\"‚úì OPENAI_API_KEY found (length: {len(api_key)})\")\n",
        "    else:\n",
        "        print(\"‚ö† WARNING: OPENAI_API_KEY not found in environment variables\")\n",
        "else:\n",
        "    # Try loading from current directory\n",
        "    load_dotenv(override=True)\n",
        "    print(\"Loaded environment variables from current directory\")\n",
        "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if api_key:\n",
        "        print(f\"‚úì OPENAI_API_KEY found (length: {len(api_key)})\")\n",
        "    else:\n",
        "        print(\"‚ö† WARNING: OPENAI_API_KEY not found in environment variables\")\n",
        "\n",
        "from src.app.Game import Game\n",
        "from src.app.Player import Player\n",
        "\n",
        "print(\"Imports successful!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mock action creator function created!\n"
          ]
        }
      ],
      "source": [
        "# Function to create a mock player action method\n",
        "def create_mock_get_action(fixed_response: str):\n",
        "    \"\"\"Create a mock get_action method that returns a fixed response\"\"\"\n",
        "    def mock_get_action(self, context: dict) -> str:\n",
        "        \"\"\"Mock version of Player.get_action that returns fixed response\"\"\"\n",
        "        self._responses.append(fixed_response)\n",
        "        return fixed_response\n",
        "    return mock_get_action\n",
        "\n",
        "print(\"Mock action creator function created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Game runner function created!\n"
          ]
        }
      ],
      "source": [
        "def run_single_game(max_turns: int, world_size: int, starting_wealth: int, \n",
        "                    fixed_responses: Dict[str, str]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Run a single game instance with fixed player responses.\n",
        "    \n",
        "    Args:\n",
        "        max_turns: Maximum number of turns\n",
        "        world_size: World size for the game\n",
        "        starting_wealth: Starting wealth for players\n",
        "        fixed_responses: Dict mapping player UID to their fixed action response\n",
        "    \n",
        "    Returns:\n",
        "        Dict with game results\n",
        "    \"\"\"\n",
        "    # Create player info (same as green agent does)\n",
        "    player_info = {\n",
        "        \"player_1\": {\n",
        "            \"uid\": \"player_1\", \n",
        "            \"position\": [0, 0], \n",
        "            \"model\": \"mock\", \n",
        "            \"player_class\": \"human\",\n",
        "            \"values\": {\"money\": starting_wealth, \"health\": 100}, \n",
        "            \"responses\": []\n",
        "        },\n",
        "        \"player_2\": {\n",
        "            \"uid\": \"player_2\", \n",
        "            \"position\": [0, 0], \n",
        "            \"model\": \"mock\", \n",
        "            \"player_class\": \"human\",\n",
        "            \"values\": {\"money\": starting_wealth, \"health\": 100}, \n",
        "            \"responses\": []\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # IMPORTANT: We do NOT mock the DM - let the real AI decide rewards\n",
        "    # We only mock player actions to ensure they're consistent\n",
        "    # This tests if the AI DM gives consistent rewards for the same player actions\n",
        "    \n",
        "    # Create game instance with real AI model (not \"mock\")\n",
        "    # The DM will use real AI to generate tiles and respond to actions\n",
        "    game = Game(player_info, {\"model\": \"gpt-4o-mini\"}, world_size)\n",
        "    \n",
        "    # Verify the DM model is set correctly (Game creates DM then loads, so verify it worked)\n",
        "    if game.dm.model != \"gpt-4o-mini\":\n",
        "        # Force set it if it didn't load correctly\n",
        "        game.dm.model = \"gpt-4o-mini\"\n",
        "    \n",
        "    # CRITICAL: Make sure we're using real AI, not mock\n",
        "    # Check if model contains \"mock\" - if so, it will use MockAiService\n",
        "    if \"mock\" in game.dm.model.lower():\n",
        "        raise ValueError(f\"ERROR: DM model is '{game.dm.model}' which will use MockAiService! Change to a real AI model like 'gpt-4o-mini'\")\n",
        "    \n",
        "    # IMPORTANT: Use unique chat_id per run to ensure no history contamination\n",
        "    # The DM uses chat_id \"DungeonMaster\" which accumulates history across runs\n",
        "    # We'll monkey-patch to use a unique chat_id for this run\n",
        "    from src.services.aiServices.wrapper import AIWrapper\n",
        "    import uuid\n",
        "    \n",
        "    # Generate unique chat_id for this run\n",
        "    unique_chat_id = f\"DM_{uuid.uuid4().hex[:8]}\"\n",
        "    \n",
        "    # Monkey-patch DM's respond_actions to use unique chat_id\n",
        "    original_respond_actions = game.dm.respond_actions\n",
        "    \n",
        "    def isolated_respond_actions(self, info: dict):\n",
        "        \"\"\"Wrapper to use unique chat_id (fresh history for each run)\"\"\"\n",
        "        from src.services.Utils import format_request\n",
        "        from core.settings import AIConfig\n",
        "        from api.apiDtoModel import GameResponse\n",
        "        \n",
        "        # Use unique chat_id - this creates a fresh service instance with no history\n",
        "        structured_response = AIWrapper.ask(\n",
        "            format_request(AIConfig.dm_prompt, info), \n",
        "            self.model, \n",
        "            unique_chat_id,  # Unique chat_id = fresh history\n",
        "            structured_output=GameResponse\n",
        "        )\n",
        "        self._responses.append(str(structured_response))\n",
        "        return structured_response\n",
        "    \n",
        "    # Replace DM's respond_actions with version that uses unique chat_id\n",
        "    game.dm.respond_actions = types.MethodType(isolated_respond_actions, game.dm)\n",
        "    \n",
        "    game.max_turns = max_turns\n",
        "    \n",
        "    # Note: Player actions are mocked (fixed), but DM uses real AI\n",
        "    # This tests if the AI DM gives consistent rewards for the same actions\n",
        "    \n",
        "    # Disable database saves to avoid database connection issues\n",
        "    # We'll override the save method temporarily to prevent database calls\n",
        "    # This is needed because Game.save() tries to save to database which may not be configured\n",
        "    def no_op_save(self):\n",
        "        # Return minimal valid JSON to avoid breaking anything that expects save() to return a string\n",
        "        # Format similar to what the real save() returns\n",
        "        import json\n",
        "        return json.dumps({\n",
        "            \"id\": \"test-game\",\n",
        "            \"status\": \"active\",\n",
        "            \"current_turn_number\": self.current_turn_number\n",
        "        })\n",
        "    game.save = types.MethodType(no_op_save, game)\n",
        "    \n",
        "    # Mock player actions to return fixed responses\n",
        "    for uid, player in game.players.items():\n",
        "        fixed_response = fixed_responses.get(uid, \"I will explore\")\n",
        "        # Replace the get_action method with our mock\n",
        "        player.get_action = types.MethodType(create_mock_get_action(fixed_response), player)\n",
        "    \n",
        "    # Track actions and rewards for bias analysis\n",
        "    turn_data = []  # Store action-reward pairs for each turn\n",
        "    \n",
        "    # Run turns (similar to green agent's loop)\n",
        "    for turn in range(max_turns):\n",
        "        if game.is_game_over:\n",
        "            break\n",
        "            \n",
        "        # Get actions from players (will use our mocked methods)\n",
        "        actions = {}\n",
        "        for role in [\"player_1\", \"player_2\"]:\n",
        "            player = game.players[role]\n",
        "            context = f\"Stats: money={player.values.money}, health={player.values.health}. Position: {player.position}. Make one action.\"\n",
        "            action = player.get_action({\n",
        "                \"Self\": player.save(),\n",
        "                \"Players (excluding self)\": {id: game.players[id].save() for id in game.players if id != role},\n",
        "                \"tiles\": game._get_viewable_tiles_payload(player.position, 1),\n",
        "                \"verdict\": \"\",\n",
        "                \"uid\": role,\n",
        "                \"position\": player.position\n",
        "            })\n",
        "            actions[role] = action\n",
        "        \n",
        "        # Store pre-verdict state for tracking\n",
        "        pre_verdict_wealth = {uid: p.values.money for uid, p in game.players.items()}\n",
        "        \n",
        "        # DM processes actions (using our mocked method)\n",
        "        verdict = game.dm.respond_actions({\n",
        "            \"Players\": {uid: game.players[uid].save() for uid in game.players},\n",
        "            \"Responses\": actions,\n",
        "            \"Past Verdict\": \"\",\n",
        "            \"tiles\": game._get_tiles_full_payload()\n",
        "        })\n",
        "        \n",
        "        # Handle verdict\n",
        "        game.handle_verdict(verdict)\n",
        "        game.current_turn_number += 1\n",
        "        game._check_game_conditions()\n",
        "        \n",
        "        # Track rewards for bias analysis\n",
        "        post_verdict_wealth = {uid: p.values.money for uid, p in game.players.items()}\n",
        "        turn_rewards = {\n",
        "            uid: post_verdict_wealth[uid] - pre_verdict_wealth[uid] \n",
        "            for uid in game.players.keys()\n",
        "        }\n",
        "        \n",
        "        turn_data.append({\n",
        "            \"turn\": turn + 1,\n",
        "            \"actions\": actions.copy(),\n",
        "            \"rewards\": turn_rewards.copy()\n",
        "        })\n",
        "        \n",
        "        if game.is_game_over:\n",
        "            break\n",
        "    \n",
        "    # Determine winner (same logic as green agent)\n",
        "    winner = None\n",
        "    max_wealth = 0\n",
        "    for uid, p in game.players.items():\n",
        "        if p.values.money > max_wealth and p.values.health > 0:\n",
        "            max_wealth, winner = p.values.money, uid\n",
        "    \n",
        "    # Return results including turn-by-turn data for bias analysis\n",
        "    return {\n",
        "        \"winner\": winner or \"none\",\n",
        "        \"final_wealth\": {uid: p.values.money for uid, p in game.players.items()},\n",
        "        \"final_health\": {uid: p.values.health for uid, p in game.players.items()},\n",
        "        \"turns_played\": game.current_turn_number,\n",
        "        \"is_game_over\": game.is_game_over,\n",
        "        \"game_over_reason\": game.game_over_reason,\n",
        "        \"turn_data\": turn_data  # For bias analysis\n",
        "    }\n",
        "\n",
        "print(\"Game runner function created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test configuration:\n",
            "  Runs: 60\n",
            "  Config: {'max_turns': 2, 'world_size': 1, 'starting_wealth': 100}\n",
            "  Fixed responses: {'player_1': 'I will move north and explore the area', 'player_2': 'I will move east and collect resources'}\n",
            "\n",
            "Note: Player actions are fixed, but the AI DM will determine rewards.\n",
            "This tests if the AI DM gives consistent rewards for the same player actions.\n"
          ]
        }
      ],
      "source": [
        "# Configuration for the test\n",
        "TEST_CONFIG = {\n",
        "    \"max_turns\": 2,  # Reduced from 3 to 2 for faster testing\n",
        "    \"world_size\": 1,\n",
        "    \"starting_wealth\": 100\n",
        "}\n",
        "\n",
        "# Fixed responses for each player (same responses used in all runs)\n",
        "FIXED_RESPONSES = {\n",
        "    \"player_1\": \"I will move north and explore the area\",\n",
        "    \"player_2\": \"I will move east and collect resources\"\n",
        "}\n",
        "\n",
        "NUM_RUNS = 60\n",
        "\n",
        "print(f\"Test configuration:\")\n",
        "print(f\"  Runs: {NUM_RUNS}\")\n",
        "print(f\"  Config: {TEST_CONFIG}\")\n",
        "print(f\"  Fixed responses: {FIXED_RESPONSES}\")\n",
        "print(\"\\nNote: Player actions are fixed, but the AI DM will determine rewards.\")\n",
        "print(\"This tests if the AI DM gives consistent rewards for the same player actions.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell is no longer needed - we use run_single_game directly from cell 3\n",
        "# Keeping this cell empty for notebook structure\n",
        "pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running 60 game evaluations in parallel...\n",
            "Max workers: 10 (adjust if needed based on API rate limits)\n",
            "This should be much faster than sequential execution!\n",
            "\n",
            "‚è∞ Started at: 2025-11-22 19:01:51\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "üì§ Submitted 60 tasks to 10 workers\n",
            "\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "[AI] Parsed structured output: position=[-1, -1] description='The terrain is a shadowy marshland enveloped in thick fog, where twisted roots emerge from murky waters and ancient stone ruins lie hidden beneath layers of moss. üå´Ô∏èü™®' secrets=[SecretKV(key='Ancient Relic of the Marsh', value=1050), SecretKV(key='Hidden Gold Cache', value=1100)] terrainType='Marsh' terrainEmoji='üåø'\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "[AI] Parsed structured output: position=[-1, 0] description=\"The terrain is a vibrant field of wildflowers swaying gently in the breeze, bordered by a sparkling river that glimmers under the sun's warm embrace. üåºüíß\" secrets=[SecretKV(key='Treasure Map Fragment', value=850), SecretKV(key='Hidden Faerie Grove', value=900)] terrainType='Field' terrainEmoji='üåæ'\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 114513, Requested 109053. Please try again in 7.069s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "‚ùå Error in run 4: AttributeError: 'NoneType' object has no attribute 'description'\n",
            "üìä [19:02:35] Progress: 1/60 (1.7%) | ‚úÖ 0 | ‚ùå 1 | ETA: 0:42:54 (0.02 runs/sec)\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "‚ùå Error in run 5: AttributeError: 'NoneType' object has no attribute 'description'\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "[AI] Parsed structured output: position=[-1, -1] description='The terrain is a shadowy marshland enveloped in thick fog, where gnarled roots twist through murky waters and ancient stone ruins rise mysteriously from the earth. üå´Ô∏èü™®' secrets=[SecretKV(key='Ancient Relic of the Marsh', value=1050), SecretKV(key='Hidden Gold Cache', value=1100)] terrainType='Marsh' terrainEmoji='üåø'\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "‚ùå Error in run 2: AttributeError: 'NoneType' object has no attribute 'description'\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "üìä [19:02:58] Progress: 5/60 (8.3%) | ‚úÖ 0 | ‚ùå 5 | ETA: 0:12:18 (0.07 runs/sec)\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "üìä [19:02:59] Progress: 10/60 (16.7%) | ‚úÖ 0 | ‚ùå 10 | ETA: 0:05:38 (0.15 runs/sec)\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109053. Please try again in 32.715s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n",
            "OpenAI API error: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o-mini in organization org-FebZig1B6MeevvIda3rg662C on tokens per min (TPM): Limit 200000, Used 200000, Requested 109539. Please try again in 32.861s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
            "[AI] Parsed structured output: None\n",
            "\n",
            "[AI] === New request ===\n",
            "[AI] Model: gpt-4o-mini\n",
            "[AI] Message: You are the Dungeon Master of a tile-based fantasy world. Always add 200 value or more to each secret in a tile.Describe the terrain at the given coordinates in one vivid, concise sentence, including one word for terrain type and two emojis. The emoj...\n",
            "[AI] Using chat session: DungeonMaster\n",
            "[AI] Initializing backend for model 'gpt-4o-mini'...\n",
            "[AI] Model supports structured output: yes\n",
            "[AI] Service ready.\n"
          ]
        }
      ],
      "source": [
        "# Run 60 game evaluations in parallel\n",
        "print(f\"Running {NUM_RUNS} game evaluations in parallel...\")\n",
        "print(f\"Max workers: 10 (adjust if needed based on API rate limits)\")\n",
        "print(\"This should be much faster than sequential execution!\\n\")\n",
        "\n",
        "# Track timing\n",
        "start_time = datetime.now()\n",
        "print(f\"‚è∞ Started at: {start_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "all_results = []\n",
        "error_counts = {}\n",
        "success_count = 0\n",
        "failure_count = 0\n",
        "\n",
        "def run_single_game_wrapper(run_number):\n",
        "    \"\"\"Wrapper function for parallel execution\"\"\"\n",
        "    try:\n",
        "        result = run_single_game(\n",
        "            max_turns=TEST_CONFIG[\"max_turns\"],\n",
        "            world_size=TEST_CONFIG[\"world_size\"],\n",
        "            starting_wealth=TEST_CONFIG[\"starting_wealth\"],\n",
        "            fixed_responses=FIXED_RESPONSES\n",
        "        )\n",
        "        return {\n",
        "            \"run_number\": run_number,\n",
        "            \"success\": True,\n",
        "            \"result\": result\n",
        "        }\n",
        "    except Exception as e:\n",
        "        error_msg = str(e)\n",
        "        error_type = type(e).__name__\n",
        "        return {\n",
        "            \"run_number\": run_number,\n",
        "            \"success\": False,\n",
        "            \"error\": error_msg,\n",
        "            \"error_type\": error_type,\n",
        "            \"result\": None\n",
        "        }\n",
        "\n",
        "# Use ThreadPoolExecutor for parallel execution\n",
        "# Using 10 workers - adjust based on your API rate limits\n",
        "max_workers = 10\n",
        "completed = 0\n",
        "last_update_time = start_time\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "    # Submit all tasks\n",
        "    future_to_run = {\n",
        "        executor.submit(run_single_game_wrapper, i + 1): i + 1 \n",
        "        for i in range(NUM_RUNS)\n",
        "    }\n",
        "    \n",
        "    print(f\"üì§ Submitted {NUM_RUNS} tasks to {max_workers} workers\\n\")\n",
        "    \n",
        "    # Process completed tasks as they finish\n",
        "    for future in as_completed(future_to_run):\n",
        "        run_number = future_to_run[future]\n",
        "        current_time = datetime.now()\n",
        "        \n",
        "        try:\n",
        "            result = future.result()\n",
        "            all_results.append(result)\n",
        "            completed += 1\n",
        "            \n",
        "            # Update success/failure counts\n",
        "            if result['success']:\n",
        "                success_count += 1\n",
        "            else:\n",
        "                failure_count += 1\n",
        "                error_type = result.get('error_type', 'Unknown')\n",
        "                error_counts[error_type] = error_counts.get(error_type, 0) + 1\n",
        "                # Print first few errors for debugging\n",
        "                if completed <= 3:\n",
        "                    error_msg = result.get('error', 'Unknown error')\n",
        "                    print(f\"‚ùå Error in run {run_number}: {error_type}: {error_msg[:200]}\")\n",
        "            \n",
        "            # Progress update every 5 completions or every 30 seconds\n",
        "            time_since_last_update = (current_time - last_update_time).total_seconds()\n",
        "            should_update = (completed % 5 == 0) or (time_since_last_update >= 30)\n",
        "            \n",
        "            if should_update:\n",
        "                elapsed = (current_time - start_time).total_seconds()\n",
        "                progress_pct = (completed / NUM_RUNS) * 100\n",
        "                \n",
        "                # Calculate ETA\n",
        "                if completed > 0:\n",
        "                    avg_time_per_run = elapsed / completed\n",
        "                    remaining_runs = NUM_RUNS - completed\n",
        "                    eta_seconds = avg_time_per_run * remaining_runs\n",
        "                    eta = timedelta(seconds=int(eta_seconds))\n",
        "                    eta_str = f\"ETA: {str(eta)}\"\n",
        "                else:\n",
        "                    eta_str = \"ETA: calculating...\"\n",
        "                \n",
        "                # Calculate rate\n",
        "                if elapsed > 0:\n",
        "                    rate = completed / elapsed\n",
        "                    rate_str = f\"({rate:.2f} runs/sec)\"\n",
        "                else:\n",
        "                    rate_str = \"\"\n",
        "                \n",
        "                print(f\"üìä [{current_time.strftime('%H:%M:%S')}] Progress: {completed}/{NUM_RUNS} ({progress_pct:.1f}%) | \"\n",
        "                      f\"‚úÖ {success_count} | ‚ùå {failure_count} | {eta_str} {rate_str}\")\n",
        "                \n",
        "                last_update_time = current_time\n",
        "                \n",
        "        except Exception as e:\n",
        "            failure_count += 1\n",
        "            error_type = type(e).__name__\n",
        "            error_counts[error_type] = error_counts.get(error_type, 0) + 1\n",
        "            print(f\"‚ùå Unexpected error processing run {run_number}: {e}\")\n",
        "            all_results.append({\n",
        "                \"run_number\": run_number,\n",
        "                \"success\": False,\n",
        "                \"error\": str(e),\n",
        "                \"error_type\": error_type,\n",
        "                \"result\": None\n",
        "            })\n",
        "\n",
        "# Sort results by run_number for consistency\n",
        "all_results.sort(key=lambda x: x['run_number'])\n",
        "\n",
        "# Final summary\n",
        "end_time = datetime.now()\n",
        "total_time = (end_time - start_time).total_seconds()\n",
        "total_time_str = str(timedelta(seconds=int(total_time)))\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"‚úÖ Completed all {NUM_RUNS} evaluations!\")\n",
        "print(f\"‚è∞ Total time: {total_time_str}\")\n",
        "print(f\"üìä Results:\")\n",
        "print(f\"   ‚úÖ Successful runs: {success_count}/{NUM_RUNS} ({success_count/NUM_RUNS*100:.1f}%)\")\n",
        "print(f\"   ‚ùå Failed runs: {failure_count}/{NUM_RUNS} ({failure_count/NUM_RUNS*100:.1f}%)\")\n",
        "if total_time > 0:\n",
        "    print(f\"   ‚ö° Average rate: {NUM_RUNS/total_time:.2f} runs/sec\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "if error_counts:\n",
        "    print(f\"\\n‚ùå Error breakdown:\")\n",
        "    for error_type, count in sorted(error_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "        print(f\"   {error_type}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total successful evaluations: 60/60\n",
            "\n",
            "============================================================\n",
            "CONSISTENCY ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Winner Distribution:\n",
            "  player_1: 60 times (100.0%)\n",
            "\n",
            "Winner Consistency: 100.0%\n",
            "  (Same winner in 60/60 runs)\n",
            "\n",
            "Final Wealth Analysis:\n",
            "  Player 1 wealth:\n",
            "    Mean: 250.00\n",
            "    Std Dev: 0.00\n",
            "    Range: 250 - 250\n",
            "    Unique values: 1\n",
            "  Player 2 wealth:\n",
            "    Mean: 250.00\n",
            "    Std Dev: 0.00\n",
            "    Range: 250 - 250\n",
            "    Unique values: 1\n",
            "\n",
            "============================================================\n",
            "DETAILED FINAL MONEY ANALYSIS\n",
            "============================================================\n",
            "\n",
            "üí∞ Theoretical Maximum Money:\n",
            "  Starting Wealth: 100\n",
            "  Max Turns: 3\n",
            "  With Mock DM (50 per turn): 250\n",
            "    Formula: 100 + (50 √ó 3) = 250\n",
            "  With Real AI DM (up to 250 per turn): 850\n",
            "    Formula: 100 + (250 √ó 3) = 850\n",
            "  Note: Current setup uses Mock DM, so max is 250\n",
            "\n",
            "üìä Player 1 Final Money Statistics:\n",
            "  Starting Wealth: 100\n",
            "  Final Wealth:\n",
            "    Mean: 250.00\n",
            "    Median: 250.00\n",
            "    Std Dev: 0.00\n",
            "    Min: 250\n",
            "    Max: 250\n",
            "    Range: 0\n",
            "    Unique values: 1/60\n",
            "  Money Earned (from starting):\n",
            "    Total across all runs: 9000.00\n",
            "    Average per run: 150.00\n",
            "    Min earned: 150\n",
            "    Max earned: 150\n",
            "  Distribution:\n",
            "    Most common final wealth: 250 (appears 60/60 times, 100.0%)\n",
            "    All wealth values:\n",
            "      250: 60 times (100.0%)\n",
            "  ‚úÖ PERFECT CONSISTENCY: All runs ended with 250 money\n",
            "  Achievement vs Maximum:\n",
            "    Highest achieved: 250 / 250 (100.0%)\n",
            "    Mean achieved: 250.00 / 250 (100.0%)\n",
            "    ‚úÖ Reached maximum possible wealth!\n",
            "\n",
            "üìä Player 2 Final Money Statistics:\n",
            "  Starting Wealth: 100\n",
            "  Final Wealth:\n",
            "    Mean: 250.00\n",
            "    Median: 250.00\n",
            "    Std Dev: 0.00\n",
            "    Min: 250\n",
            "    Max: 250\n",
            "    Range: 0\n",
            "    Unique values: 1/60\n",
            "  Money Earned (from starting):\n",
            "    Total across all runs: 9000.00\n",
            "    Average per run: 150.00\n",
            "    Min earned: 150\n",
            "    Max earned: 150\n",
            "  Distribution:\n",
            "    Most common final wealth: 250 (appears 60/60 times, 100.0%)\n",
            "    All wealth values:\n",
            "      250: 60 times (100.0%)\n",
            "  ‚úÖ PERFECT CONSISTENCY: All runs ended with 250 money\n",
            "  Achievement vs Maximum:\n",
            "    Highest achieved: 250 / 250 (100.0%)\n",
            "    Mean achieved: 250.00 / 250 (100.0%)\n",
            "    ‚úÖ Reached maximum possible wealth!\n",
            "\n",
            "üìà Comparative Analysis:\n",
            "  Average final wealth:\n",
            "    Player 1: 250.00\n",
            "    Player 2: 250.00\n",
            "    Difference: 0.00\n",
            "    Both players have equal average wealth\n",
            "  Total wealth across all runs:\n",
            "    Player 1: 15000.00\n",
            "    Player 2: 15000.00\n",
            "  Runs where both players ended with same wealth: 60/60 (100.0%)\n",
            "\n",
            "Final Health Analysis:\n",
            "  Player 1 health:\n",
            "    Mean: 115.00\n",
            "    Std Dev: 0.00\n",
            "    Range: 115 - 115\n",
            "    Unique values: 1\n",
            "  Player 2 health:\n",
            "    Mean: 115.00\n",
            "    Std Dev: 0.00\n",
            "    Range: 115 - 115\n",
            "    Unique values: 1\n",
            "\n",
            "Turns Played Analysis:\n",
            "  Mean: 3.00\n",
            "  Std Dev: 0.00\n",
            "  Range: 3 - 3\n",
            "  Unique values: 1\n",
            "\n",
            "============================================================\n",
            "OVERALL CONSISTENCY ASSESSMENT\n",
            "============================================================\n",
            "\n",
            "Consistency Score: 100.0%\n",
            "  - Winner consistency: 100.0%\n",
            "  - Wealth consistency: 100.0%\n",
            "  - Health consistency: 100.0%\n",
            "  - Turns consistency: 100.0%\n",
            "\n",
            "‚úÖ HIGH CONSISTENCY: Results are very similar across runs\n",
            "\n",
            "============================================================\n",
            "BIAS ANALYSIS: Action-Reward Consistency\n",
            "============================================================\n",
            "\n",
            "Analyzing 2 unique actions across all runs...\n",
            "\n",
            "‚úÖ Consistent Actions (same reward every time): 2\n",
            "‚ö†Ô∏è  Potentially Biased Actions (different rewards): 0\n",
            "\n",
            "Consistent Actions (showing first 5):\n",
            "  'I will move north and explore the area...' ‚Üí 50 money (180 times)\n",
            "  'I will move east and collect resources...' ‚Üí 50 money (180 times)\n",
            "\n",
            "============================================================\n",
            "AVERAGE REWARDS BY ACTION\n",
            "============================================================\n",
            "\n",
            "'I will move north and explore the area...'\n",
            "  Count: 180\n",
            "  Average Reward: 50.00 money\n",
            "  Std Deviation: 0.00\n",
            "  Range: 50 - 50\n",
            "\n",
            "'I will move east and collect resources...'\n",
            "  Count: 180\n",
            "  Average Reward: 50.00 money\n",
            "  Std Deviation: 0.00\n",
            "  Range: 50 - 50\n",
            "\n",
            "============================================================\n",
            "BIAS SUMMARY\n",
            "============================================================\n",
            "\n",
            "Total action instances: 360\n",
            "Consistent rewards: 360 (100.0%)\n",
            "Variable rewards: 0 (0.0%)\n",
            "\n",
            "‚úÖ EXCELLENT: Judge is highly consistent - same actions get same rewards\n"
          ]
        }
      ],
      "source": [
        "# Extract and analyze results\n",
        "successful_results = [r for r in all_results if r['success'] and r['result']]\n",
        "\n",
        "print(f\"Total successful evaluations: {len(successful_results)}/{NUM_RUNS}\\n\")\n",
        "\n",
        "if len(successful_results) == 0:\n",
        "    print(\"No successful evaluations! Check errors above.\")\n",
        "else:\n",
        "    # Parse results\n",
        "    winners = []\n",
        "    final_wealths = []\n",
        "    final_healths = []\n",
        "    turns_played = []\n",
        "    all_turn_data = []  # For bias analysis\n",
        "    \n",
        "    for result_data in successful_results:\n",
        "        result = result_data['result']\n",
        "        \n",
        "        # Extract winner\n",
        "        winner = result.get('winner', 'unknown')\n",
        "        winners.append(winner)\n",
        "        \n",
        "        # Extract details (directly from result, not nested in 'detail')\n",
        "        final_wealth = result.get('final_wealth', {})\n",
        "        final_health = result.get('final_health', {})\n",
        "        turns = result.get('turns_played', 0)\n",
        "        turn_data = result.get('turn_data', [])\n",
        "        \n",
        "        final_wealths.append(final_wealth)\n",
        "        final_healths.append(final_health)\n",
        "        turns_played.append(turns)\n",
        "        all_turn_data.append(turn_data)\n",
        "    \n",
        "    # Analyze consistency\n",
        "    print(\"=\" * 60)\n",
        "    print(\"CONSISTENCY ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Winner consistency\n",
        "    winner_counts = Counter(winners)\n",
        "    print(f\"\\nWinner Distribution:\")\n",
        "    for winner, count in winner_counts.most_common():\n",
        "        percentage = (count / len(winners)) * 100\n",
        "        print(f\"  {winner}: {count} times ({percentage:.1f}%)\")\n",
        "    \n",
        "    # Check if winner is consistent\n",
        "    most_common_winner, most_common_count = winner_counts.most_common(1)[0]\n",
        "    winner_consistency = (most_common_count / len(winners)) * 100\n",
        "    print(f\"\\nWinner Consistency: {winner_consistency:.1f}%\")\n",
        "    print(f\"  (Same winner in {most_common_count}/{len(winners)} runs)\")\n",
        "    \n",
        "    # Wealth consistency\n",
        "    print(f\"\\nFinal Wealth Analysis:\")\n",
        "    if final_wealths:\n",
        "        player_1_wealths = [w.get('player_1', 0) for w in final_wealths if 'player_1' in w]\n",
        "        player_2_wealths = [w.get('player_2', 0) for w in final_wealths if 'player_2' in w]\n",
        "        \n",
        "        if player_1_wealths:\n",
        "            print(f\"  Player 1 wealth:\")\n",
        "            print(f\"    Mean: {statistics.mean(player_1_wealths):.2f}\")\n",
        "            print(f\"    Std Dev: {statistics.stdev(player_1_wealths) if len(player_1_wealths) > 1 else 0:.2f}\")\n",
        "            print(f\"    Range: {min(player_1_wealths)} - {max(player_1_wealths)}\")\n",
        "            print(f\"    Unique values: {len(set(player_1_wealths))}\")\n",
        "        \n",
        "        if player_2_wealths:\n",
        "            print(f\"  Player 2 wealth:\")\n",
        "            print(f\"    Mean: {statistics.mean(player_2_wealths):.2f}\")\n",
        "            print(f\"    Std Dev: {statistics.stdev(player_2_wealths) if len(player_2_wealths) > 1 else 0:.2f}\")\n",
        "            print(f\"    Range: {min(player_2_wealths)} - {max(player_2_wealths)}\")\n",
        "            print(f\"    Unique values: {len(set(player_2_wealths))}\")\n",
        "    \n",
        "    # ============================================================\n",
        "    # DETAILED MONEY ANALYSIS\n",
        "    # ============================================================\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"DETAILED FINAL MONEY ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    if final_wealths:\n",
        "        starting_wealth = TEST_CONFIG.get(\"starting_wealth\", 100)\n",
        "        max_turns = TEST_CONFIG.get(\"max_turns\", 3)\n",
        "        \n",
        "        # Calculate theoretical maximum\n",
        "        # According to DM prompt: \"give money_change = +50 to +250 (taken from tile secrets)\"\n",
        "        # So the maximum reward per turn is 250\n",
        "        # Maximum final wealth = starting_wealth + (250 * max_turns)\n",
        "        max_reward_per_turn = 250  # Maximum per DM prompt\n",
        "        theoretical_max = starting_wealth + (max_reward_per_turn * max_turns)\n",
        "        \n",
        "        print(f\"\\nüí∞ Theoretical Maximum Money:\")\n",
        "        print(f\"  Starting Wealth: {starting_wealth}\")\n",
        "        print(f\"  Max Turns: {max_turns}\")\n",
        "        print(f\"  Maximum Reward Per Turn: {max_reward_per_turn} (according to DM prompt)\")\n",
        "        print(f\"  Theoretical Maximum Final Wealth: {theoretical_max}\")\n",
        "        print(f\"    Formula: {starting_wealth} + ({max_reward_per_turn} √ó {max_turns}) = {theoretical_max}\")\n",
        "        print(f\"  Note: DM prompt allows money_change from +50 to +250 per turn\")\n",
        "        \n",
        "        # Player 1 detailed analysis\n",
        "        if player_1_wealths:\n",
        "            p1_mean = statistics.mean(player_1_wealths)\n",
        "            p1_std = statistics.stdev(player_1_wealths) if len(player_1_wealths) > 1 else 0\n",
        "            p1_min = min(player_1_wealths)\n",
        "            p1_max = max(player_1_wealths)\n",
        "            p1_median = statistics.median(player_1_wealths)\n",
        "            p1_unique = len(set(player_1_wealths))\n",
        "            p1_total_earned = sum(w - starting_wealth for w in player_1_wealths)\n",
        "            p1_avg_earned = p1_mean - starting_wealth\n",
        "            \n",
        "            # Wealth distribution\n",
        "            p1_wealth_counts = Counter(player_1_wealths)\n",
        "            p1_most_common_wealth, p1_most_common_count = p1_wealth_counts.most_common(1)[0]\n",
        "            p1_most_common_pct = (p1_most_common_count / len(player_1_wealths)) * 100\n",
        "            \n",
        "            print(f\"\\nüìä Player 1 Final Money Statistics:\")\n",
        "            print(f\"  Starting Wealth: {starting_wealth}\")\n",
        "            print(f\"  Final Wealth:\")\n",
        "            print(f\"    Mean: {p1_mean:.2f}\")\n",
        "            print(f\"    Median: {p1_median:.2f}\")\n",
        "            print(f\"    Std Dev: {p1_std:.2f}\")\n",
        "            print(f\"    Min: {p1_min}\")\n",
        "            print(f\"    Max: {p1_max}\")\n",
        "            print(f\"    Range: {p1_max - p1_min}\")\n",
        "            print(f\"    Unique values: {p1_unique}/{len(player_1_wealths)}\")\n",
        "            print(f\"  Money Earned (from starting):\")\n",
        "            print(f\"    Total across all runs: {p1_total_earned:.2f}\")\n",
        "            print(f\"    Average per run: {p1_avg_earned:.2f}\")\n",
        "            print(f\"    Min earned: {p1_min - starting_wealth}\")\n",
        "            print(f\"    Max earned: {p1_max - starting_wealth}\")\n",
        "            print(f\"  Distribution:\")\n",
        "            print(f\"    Most common final wealth: {p1_most_common_wealth} (appears {p1_most_common_count}/{len(player_1_wealths)} times, {p1_most_common_pct:.1f}%)\")\n",
        "            if p1_unique <= 10:\n",
        "                print(f\"    All wealth values:\")\n",
        "                for wealth, count in sorted(p1_wealth_counts.items()):\n",
        "                    pct = (count / len(player_1_wealths)) * 100\n",
        "                    print(f\"      {wealth}: {count} times ({pct:.1f}%)\")\n",
        "            \n",
        "            # Consistency assessment\n",
        "            if p1_unique == 1:\n",
        "                print(f\"  ‚úÖ PERFECT CONSISTENCY: All runs ended with {player_1_wealths[0]} money\")\n",
        "            elif p1_std < 1.0:\n",
        "                print(f\"  ‚úÖ HIGH CONSISTENCY: Very low variance (std: {p1_std:.2f})\")\n",
        "            elif p1_std < 5.0:\n",
        "                print(f\"  ‚ö†Ô∏è  MODERATE CONSISTENCY: Some variance (std: {p1_std:.2f})\")\n",
        "            else:\n",
        "                print(f\"  ‚ùå LOW CONSISTENCY: High variance (std: {p1_std:.2f})\")\n",
        "            \n",
        "            # Achievement vs maximum\n",
        "            achievement_pct = (p1_max / theoretical_max) * 100\n",
        "            mean_achievement_pct = (p1_mean / theoretical_max) * 100\n",
        "            print(f\"  Achievement vs Maximum:\")\n",
        "            print(f\"    Highest achieved: {p1_max} / {theoretical_max} ({achievement_pct:.1f}%)\")\n",
        "            print(f\"    Mean achieved: {p1_mean:.2f} / {theoretical_max} ({mean_achievement_pct:.1f}%)\")\n",
        "            if p1_max == theoretical_max:\n",
        "                print(f\"    ‚úÖ Reached maximum possible wealth!\")\n",
        "            elif achievement_pct >= 95:\n",
        "                print(f\"    ‚úÖ Very close to maximum (within 5%)\")\n",
        "            elif achievement_pct >= 80:\n",
        "                print(f\"    ‚ö†Ô∏è  Close to maximum but not quite there\")\n",
        "            else:\n",
        "                print(f\"    ‚ùå Significantly below maximum\")\n",
        "        \n",
        "        # Player 2 detailed analysis\n",
        "        if player_2_wealths:\n",
        "            p2_mean = statistics.mean(player_2_wealths)\n",
        "            p2_std = statistics.stdev(player_2_wealths) if len(player_2_wealths) > 1 else 0\n",
        "            p2_min = min(player_2_wealths)\n",
        "            p2_max = max(player_2_wealths)\n",
        "            p2_median = statistics.median(player_2_wealths)\n",
        "            p2_unique = len(set(player_2_wealths))\n",
        "            p2_total_earned = sum(w - starting_wealth for w in player_2_wealths)\n",
        "            p2_avg_earned = p2_mean - starting_wealth\n",
        "            \n",
        "            # Wealth distribution\n",
        "            p2_wealth_counts = Counter(player_2_wealths)\n",
        "            p2_most_common_wealth, p2_most_common_count = p2_wealth_counts.most_common(1)[0]\n",
        "            p2_most_common_pct = (p2_most_common_count / len(player_2_wealths)) * 100\n",
        "            \n",
        "            print(f\"\\nüìä Player 2 Final Money Statistics:\")\n",
        "            print(f\"  Starting Wealth: {starting_wealth}\")\n",
        "            print(f\"  Final Wealth:\")\n",
        "            print(f\"    Mean: {p2_mean:.2f}\")\n",
        "            print(f\"    Median: {p2_median:.2f}\")\n",
        "            print(f\"    Std Dev: {p2_std:.2f}\")\n",
        "            print(f\"    Min: {p2_min}\")\n",
        "            print(f\"    Max: {p2_max}\")\n",
        "            print(f\"    Range: {p2_max - p2_min}\")\n",
        "            print(f\"    Unique values: {p2_unique}/{len(player_2_wealths)}\")\n",
        "            print(f\"  Money Earned (from starting):\")\n",
        "            print(f\"    Total across all runs: {p2_total_earned:.2f}\")\n",
        "            print(f\"    Average per run: {p2_avg_earned:.2f}\")\n",
        "            print(f\"    Min earned: {p2_min - starting_wealth}\")\n",
        "            print(f\"    Max earned: {p2_max - starting_wealth}\")\n",
        "            print(f\"  Distribution:\")\n",
        "            print(f\"    Most common final wealth: {p2_most_common_wealth} (appears {p2_most_common_count}/{len(player_2_wealths)} times, {p2_most_common_pct:.1f}%)\")\n",
        "            if p2_unique <= 10:\n",
        "                print(f\"    All wealth values:\")\n",
        "                for wealth, count in sorted(p2_wealth_counts.items()):\n",
        "                    pct = (count / len(player_2_wealths)) * 100\n",
        "                    print(f\"      {wealth}: {count} times ({pct:.1f}%)\")\n",
        "            \n",
        "            # Consistency assessment\n",
        "            if p2_unique == 1:\n",
        "                print(f\"  ‚úÖ PERFECT CONSISTENCY: All runs ended with {player_2_wealths[0]} money\")\n",
        "            elif p2_std < 1.0:\n",
        "                print(f\"  ‚úÖ HIGH CONSISTENCY: Very low variance (std: {p2_std:.2f})\")\n",
        "            elif p2_std < 5.0:\n",
        "                print(f\"  ‚ö†Ô∏è  MODERATE CONSISTENCY: Some variance (std: {p2_std:.2f})\")\n",
        "            else:\n",
        "                print(f\"  ‚ùå LOW CONSISTENCY: High variance (std: {p2_std:.2f})\")\n",
        "            \n",
        "            # Achievement vs maximum\n",
        "            achievement_pct = (p2_max / theoretical_max) * 100\n",
        "            mean_achievement_pct = (p2_mean / theoretical_max) * 100\n",
        "            print(f\"  Achievement vs Maximum:\")\n",
        "            print(f\"    Highest achieved: {p2_max} / {theoretical_max} ({achievement_pct:.1f}%)\")\n",
        "            print(f\"    Mean achieved: {p2_mean:.2f} / {theoretical_max} ({mean_achievement_pct:.1f}%)\")\n",
        "            if p2_max == theoretical_max:\n",
        "                print(f\"    ‚úÖ Reached maximum possible wealth!\")\n",
        "            elif achievement_pct >= 95:\n",
        "                print(f\"    ‚úÖ Very close to maximum (within 5%)\")\n",
        "            elif achievement_pct >= 80:\n",
        "                print(f\"    ‚ö†Ô∏è  Close to maximum but not quite there\")\n",
        "            else:\n",
        "                print(f\"    ‚ùå Significantly below maximum\")\n",
        "        \n",
        "        # Comparative analysis\n",
        "        if player_1_wealths and player_2_wealths:\n",
        "            print(f\"\\nüìà Comparative Analysis:\")\n",
        "            p1_mean = statistics.mean(player_1_wealths)\n",
        "            p2_mean = statistics.mean(player_2_wealths)\n",
        "            p1_total = sum(player_1_wealths)\n",
        "            p2_total = sum(player_2_wealths)\n",
        "            \n",
        "            print(f\"  Average final wealth:\")\n",
        "            print(f\"    Player 1: {p1_mean:.2f}\")\n",
        "            print(f\"    Player 2: {p2_mean:.2f}\")\n",
        "            print(f\"    Difference: {abs(p1_mean - p2_mean):.2f}\")\n",
        "            \n",
        "            if p1_mean > p2_mean:\n",
        "                advantage = ((p1_mean - p2_mean) / p2_mean) * 100\n",
        "                print(f\"    Player 1 has {advantage:.1f}% more money on average\")\n",
        "            elif p2_mean > p1_mean:\n",
        "                advantage = ((p2_mean - p1_mean) / p1_mean) * 100\n",
        "                print(f\"    Player 2 has {advantage:.1f}% more money on average\")\n",
        "            else:\n",
        "                print(f\"    Both players have equal average wealth\")\n",
        "            \n",
        "            print(f\"  Total wealth across all runs:\")\n",
        "            print(f\"    Player 1: {p1_total:.2f}\")\n",
        "            print(f\"    Player 2: {p2_total:.2f}\")\n",
        "            \n",
        "            # Check if players end with same wealth\n",
        "            same_wealth_count = sum(1 for w1, w2 in zip(player_1_wealths, player_2_wealths) if w1 == w2)\n",
        "            same_wealth_pct = (same_wealth_count / len(player_1_wealths)) * 100\n",
        "            print(f\"  Runs where both players ended with same wealth: {same_wealth_count}/{len(player_1_wealths)} ({same_wealth_pct:.1f}%)\")\n",
        "    \n",
        "    # Health consistency\n",
        "    print(f\"\\nFinal Health Analysis:\")\n",
        "    if final_healths:\n",
        "        player_1_healths = [h.get('player_1', 0) for h in final_healths if 'player_1' in h]\n",
        "        player_2_healths = [h.get('player_2', 0) for h in final_healths if 'player_2' in h]\n",
        "        \n",
        "        if player_1_healths:\n",
        "            print(f\"  Player 1 health:\")\n",
        "            print(f\"    Mean: {statistics.mean(player_1_healths):.2f}\")\n",
        "            print(f\"    Std Dev: {statistics.stdev(player_1_healths) if len(player_1_healths) > 1 else 0:.2f}\")\n",
        "            print(f\"    Range: {min(player_1_healths)} - {max(player_1_healths)}\")\n",
        "            print(f\"    Unique values: {len(set(player_1_healths))}\")\n",
        "        \n",
        "        if player_2_healths:\n",
        "            print(f\"  Player 2 health:\")\n",
        "            print(f\"    Mean: {statistics.mean(player_2_healths):.2f}\")\n",
        "            print(f\"    Std Dev: {statistics.stdev(player_2_healths) if len(player_2_healths) > 1 else 0:.2f}\")\n",
        "            print(f\"    Range: {min(player_2_healths)} - {max(player_2_healths)}\")\n",
        "            print(f\"    Unique values: {len(set(player_2_healths))}\")\n",
        "    \n",
        "    # Turns consistency\n",
        "    print(f\"\\nTurns Played Analysis:\")\n",
        "    if turns_played:\n",
        "        print(f\"  Mean: {statistics.mean(turns_played):.2f}\")\n",
        "        print(f\"  Std Dev: {statistics.stdev(turns_played) if len(turns_played) > 1 else 0:.2f}\")\n",
        "        print(f\"  Range: {min(turns_played)} - {max(turns_played)}\")\n",
        "        print(f\"  Unique values: {len(set(turns_played))}\")\n",
        "    \n",
        "    # Overall consistency score\n",
        "    print(f\"\\n\" + \"=\" * 60)\n",
        "    print(\"OVERALL CONSISTENCY ASSESSMENT\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Calculate consistency metrics\n",
        "    wealth_consistency = 0\n",
        "    if player_1_wealths and len(set(player_1_wealths)) == 1:\n",
        "        wealth_consistency += 0.5\n",
        "    if player_2_wealths and len(set(player_2_wealths)) == 1:\n",
        "        wealth_consistency += 0.5\n",
        "    \n",
        "    health_consistency = 0\n",
        "    if player_1_healths and len(set(player_1_healths)) == 1:\n",
        "        health_consistency += 0.5\n",
        "    if player_2_healths and len(set(player_2_healths)) == 1:\n",
        "        health_consistency += 0.5\n",
        "    \n",
        "    turns_consistency = 1.0 if len(set(turns_played)) == 1 else 0.0\n",
        "    \n",
        "    overall_score = (winner_consistency / 100 * 0.4 + \n",
        "                    wealth_consistency * 0.3 + \n",
        "                    health_consistency * 0.2 + \n",
        "                    turns_consistency * 0.1)\n",
        "    \n",
        "    print(f\"\\nConsistency Score: {overall_score * 100:.1f}%\")\n",
        "    print(f\"  - Winner consistency: {winner_consistency:.1f}%\")\n",
        "    print(f\"  - Wealth consistency: {wealth_consistency * 100:.1f}%\")\n",
        "    print(f\"  - Health consistency: {health_consistency * 100:.1f}%\")\n",
        "    print(f\"  - Turns consistency: {turns_consistency * 100:.1f}%\")\n",
        "    \n",
        "    if overall_score >= 0.9:\n",
        "        print(\"\\n‚úÖ HIGH CONSISTENCY: Results are very similar across runs\")\n",
        "    elif overall_score >= 0.7:\n",
        "        print(\"\\n‚ö†Ô∏è  MODERATE CONSISTENCY: Some variation in results\")\n",
        "    else:\n",
        "        print(\"\\n‚ùå LOW CONSISTENCY: Significant variation in results\")\n",
        "    \n",
        "    # ============================================================\n",
        "    # BIAS ANALYSIS: Check if same actions get same rewards\n",
        "    # ============================================================\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"BIAS ANALYSIS: Action-Reward Consistency\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Group rewards by action text\n",
        "    action_reward_map = {}  # action_text -> list of rewards\n",
        "    \n",
        "    for run_idx, turn_data in enumerate(all_turn_data):\n",
        "        for turn_info in turn_data:\n",
        "            actions = turn_info.get('actions', {})\n",
        "            rewards = turn_info.get('rewards', {})\n",
        "            \n",
        "            for player_id, action_text in actions.items():\n",
        "                reward = rewards.get(player_id, 0)\n",
        "                \n",
        "                if action_text not in action_reward_map:\n",
        "                    action_reward_map[action_text] = []\n",
        "                action_reward_map[action_text].append({\n",
        "                    'reward': reward,\n",
        "                    'player': player_id,\n",
        "                    'run': run_idx,\n",
        "                    'turn': turn_info.get('turn', 0)\n",
        "                })\n",
        "    \n",
        "    # Analyze bias: same actions should get same rewards\n",
        "    print(f\"\\nAnalyzing {len(action_reward_map)} unique actions across all runs...\\n\")\n",
        "    \n",
        "    biased_actions = []\n",
        "    consistent_actions = []\n",
        "    \n",
        "    for action_text, reward_data in action_reward_map.items():\n",
        "        rewards = [r['reward'] for r in reward_data]\n",
        "        unique_rewards = set(rewards)\n",
        "        \n",
        "        if len(unique_rewards) == 1:\n",
        "            # All same reward - consistent\n",
        "            consistent_actions.append({\n",
        "                'action': action_text,\n",
        "                'reward': rewards[0],\n",
        "                'count': len(rewards)\n",
        "            })\n",
        "        else:\n",
        "            # Different rewards for same action - potential bias\n",
        "            biased_actions.append({\n",
        "                'action': action_text,\n",
        "                'rewards': rewards,\n",
        "                'unique_rewards': list(unique_rewards),\n",
        "                'mean': statistics.mean(rewards),\n",
        "                'std_dev': statistics.stdev(rewards) if len(rewards) > 1 else 0,\n",
        "                'min': min(rewards),\n",
        "                'max': max(rewards),\n",
        "                'count': len(rewards)\n",
        "            })\n",
        "    \n",
        "    print(f\"‚úÖ Consistent Actions (same reward every time): {len(consistent_actions)}\")\n",
        "    print(f\"‚ö†Ô∏è  Potentially Biased Actions (different rewards): {len(biased_actions)}\\n\")\n",
        "    \n",
        "    if consistent_actions:\n",
        "        print(\"Consistent Actions (showing first 5):\")\n",
        "        for action_info in consistent_actions[:5]:\n",
        "            print(f\"  '{action_info['action'][:50]}...' ‚Üí {action_info['reward']} money ({action_info['count']} times)\")\n",
        "    \n",
        "    if biased_actions:\n",
        "        print(f\"\\n‚ö†Ô∏è  Potentially Biased Actions (showing all {len(biased_actions)}):\")\n",
        "        for action_info in biased_actions:\n",
        "            print(f\"\\n  Action: '{action_info['action'][:60]}...'\")\n",
        "            print(f\"    Occurrences: {action_info['count']}\")\n",
        "            print(f\"    Reward Range: {action_info['min']} to {action_info['max']}\")\n",
        "            print(f\"    Mean Reward: {action_info['mean']:.2f}\")\n",
        "            print(f\"    Std Dev: {action_info['std_dev']:.2f}\")\n",
        "            print(f\"    Unique Rewards: {action_info['unique_rewards']}\")\n",
        "    \n",
        "    # Calculate average rewards per action\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"AVERAGE REWARDS BY ACTION\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for action_text, reward_data in sorted(action_reward_map.items(), key=lambda x: -len(x[1])):\n",
        "        rewards = [r['reward'] for r in reward_data]\n",
        "        avg_reward = statistics.mean(rewards)\n",
        "        std_reward = statistics.stdev(rewards) if len(rewards) > 1 else 0\n",
        "        \n",
        "        print(f\"\\n'{action_text[:60]}...'\")\n",
        "        print(f\"  Count: {len(rewards)}\")\n",
        "        print(f\"  Average Reward: {avg_reward:.2f} money\")\n",
        "        print(f\"  Std Deviation: {std_reward:.2f}\")\n",
        "        print(f\"  Range: {min(rewards)} - {max(rewards)}\")\n",
        "    \n",
        "    # Overall bias summary\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"BIAS SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    total_actions = sum(len(rd) for rd in action_reward_map.values())\n",
        "    consistent_count = sum(len(rd) for action, rd in action_reward_map.items() if len(set(r['reward'] for r in rd)) == 1)\n",
        "    biased_count = total_actions - consistent_count\n",
        "    \n",
        "    consistency_percentage = (consistent_count / total_actions * 100) if total_actions > 0 else 0\n",
        "    \n",
        "    print(f\"\\nTotal action instances: {total_actions}\")\n",
        "    print(f\"Consistent rewards: {consistent_count} ({consistency_percentage:.1f}%)\")\n",
        "    print(f\"Variable rewards: {biased_count} ({100 - consistency_percentage:.1f}%)\")\n",
        "    \n",
        "    if consistency_percentage >= 95:\n",
        "        print(\"\\n‚úÖ EXCELLENT: Judge is highly consistent - same actions get same rewards\")\n",
        "    elif consistency_percentage >= 80:\n",
        "        print(\"\\n‚ö†Ô∏è  MODERATE: Judge shows some variation - most actions get consistent rewards\")\n",
        "    else:\n",
        "        print(\"\\n‚ùå HIGH VARIANCE: Judge shows significant bias - same actions get different rewards\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Results (first 5 successful runs):\n",
            "\n",
            "Run 1:\n",
            "  Winner: player_1\n",
            "  Final Wealth: {'player_1': 250, 'player_2': 250}\n",
            "  Final Health: {'player_1': 115, 'player_2': 115}\n",
            "  Turns Played: 3\n",
            "  Game Over: True\n",
            "------------------------------------------------------------\n",
            "Run 2:\n",
            "  Winner: player_1\n",
            "  Final Wealth: {'player_1': 250, 'player_2': 250}\n",
            "  Final Health: {'player_1': 115, 'player_2': 115}\n",
            "  Turns Played: 3\n",
            "  Game Over: True\n",
            "------------------------------------------------------------\n",
            "Run 3:\n",
            "  Winner: player_1\n",
            "  Final Wealth: {'player_1': 250, 'player_2': 250}\n",
            "  Final Health: {'player_1': 115, 'player_2': 115}\n",
            "  Turns Played: 3\n",
            "  Game Over: True\n",
            "------------------------------------------------------------\n",
            "Run 4:\n",
            "  Winner: player_1\n",
            "  Final Wealth: {'player_1': 250, 'player_2': 250}\n",
            "  Final Health: {'player_1': 115, 'player_2': 115}\n",
            "  Turns Played: 3\n",
            "  Game Over: True\n",
            "------------------------------------------------------------\n",
            "Run 5:\n",
            "  Winner: player_1\n",
            "  Final Wealth: {'player_1': 250, 'player_2': 250}\n",
            "  Final Health: {'player_1': 115, 'player_2': 115}\n",
            "  Turns Played: 3\n",
            "  Game Over: True\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Display sample results for inspection\n",
        "print(\"Sample Results (first 5 successful runs):\\n\")\n",
        "for i, result_data in enumerate(successful_results[:5]):\n",
        "    print(f\"Run {result_data['run_number']}:\")\n",
        "    result = result_data['result']\n",
        "    print(f\"  Winner: {result.get('winner', 'unknown')}\")\n",
        "    print(f\"  Final Wealth: {result.get('final_wealth', {})}\")\n",
        "    print(f\"  Final Health: {result.get('final_health', {})}\")\n",
        "    print(f\"  Turns Played: {result.get('turns_played', 0)}\")\n",
        "    print(f\"  Game Over: {result.get('is_game_over', False)}\")\n",
        "    print(\"-\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show detailed error information for debugging\n",
        "failed_runs = [r for r in all_results if not r['success']]\n",
        "if failed_runs:\n",
        "    print(f\"\\nDetailed Error Information (first 3 failures):\")\n",
        "    for i, failed in enumerate(failed_runs[:3]):\n",
        "        print(f\"\\n--- Run {failed['run_number']} ---\")\n",
        "        print(f\"Error Type: {failed.get('error_type', 'Unknown')}\")\n",
        "        print(f\"Error Message: {failed.get('error', 'Unknown error')}\")\n",
        "        if len(failed.get('error', '')) > 500:\n",
        "            print(f\"(Error message truncated, full length: {len(failed.get('error', ''))})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing a single game run with detailed error handling...\n",
            "\n",
            "[Game] Game ended: Maximum turns reached (3/3)\n",
            "‚úÖ Single test run successful!\n",
            "Result: {'winner': 'player_1', 'final_wealth': {'player_1': 250, 'player_2': 250}, 'final_health': {'player_1': 115, 'player_2': 115}, 'turns_played': 3, 'is_game_over': True, 'game_over_reason': 'Maximum turns reached (3/3)', 'turn_data': [{'turn': 1, 'actions': {'player_1': 'I will move north and explore the area', 'player_2': 'I will move east and collect resources'}, 'rewards': {'player_1': 50, 'player_2': 50}}, {'turn': 2, 'actions': {'player_1': 'I will move north and explore the area', 'player_2': 'I will move east and collect resources'}, 'rewards': {'player_1': 50, 'player_2': 50}}, {'turn': 3, 'actions': {'player_1': 'I will move north and explore the area', 'player_2': 'I will move east and collect resources'}, 'rewards': {'player_1': 50, 'player_2': 50}}]}\n"
          ]
        }
      ],
      "source": [
        "# Test a single run with detailed error reporting\n",
        "print(\"Testing a single game run with detailed error handling...\\n\")\n",
        "\n",
        "try:\n",
        "    import traceback\n",
        "    result = run_single_game(\n",
        "        max_turns=TEST_CONFIG[\"max_turns\"],\n",
        "        world_size=TEST_CONFIG[\"world_size\"],\n",
        "        starting_wealth=TEST_CONFIG[\"starting_wealth\"],\n",
        "        fixed_responses=FIXED_RESPONSES\n",
        "    )\n",
        "    print(\"‚úÖ Single test run successful!\")\n",
        "    print(f\"Result: {result}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Single test run failed!\")\n",
        "    print(f\"Error Type: {type(e).__name__}\")\n",
        "    print(f\"Error Message: {str(e)}\")\n",
        "    print(\"\\nFull traceback:\")\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "AI-BASED EVAL SERVICE CONSISTENCY TEST\n",
            "============================================================\n",
            "Testing if the AI evaluator gives consistent scores for the same inputs\n",
            "\n",
            "Configuration:\n",
            "  Runs: 60\n",
            "  Service Type: custom (AI-based)\n",
            "  AI Model: gpt-4o-mini\n",
            "  Environment: You are a customer service agent. A customer is complaining about a delayed orde...\n",
            "  Response: I sincerely apologize for the inconvenience. Let me immediately check your order...\n",
            "\n",
            "Note: Using real AI model with environment variables loaded from backend/.env\n",
            "\n",
            "Completed 10/60 evaluations...\n",
            "Completed 20/60 evaluations...\n",
            "Completed 30/60 evaluations...\n",
            "Completed 40/60 evaluations...\n",
            "Completed 50/60 evaluations...\n",
            "Completed 60/60 evaluations...\n",
            "\n",
            "Eval Service Results:\n",
            "  Successful: 60/60\n",
            "  Failed: 0/60\n"
          ]
        }
      ],
      "source": [
        "# Test AI-based Eval Service\n",
        "from eval import EvalWrapper, quick_evaluate\n",
        "\n",
        "# Test configuration\n",
        "TEST_ENVIRONMENT = \"You are a customer service agent. A customer is complaining about a delayed order and is very upset.\"\n",
        "TEST_RESPONSE = \"I sincerely apologize for the inconvenience. Let me immediately check your order status and provide you with an updated timeline. I understand your frustration and want to resolve this quickly.\"\n",
        "\n",
        "EVAL_NUM_RUNS = 60\n",
        "EVAL_AI_MODEL = \"gpt-4o-mini\"  # AI model to use for evaluation\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"AI-BASED EVAL SERVICE CONSISTENCY TEST\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Testing if the AI evaluator gives consistent scores for the same inputs\")\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Runs: {EVAL_NUM_RUNS}\")\n",
        "print(f\"  Service Type: custom (AI-based)\")\n",
        "print(f\"  AI Model: {EVAL_AI_MODEL}\")\n",
        "print(f\"  Environment: {TEST_ENVIRONMENT[:80]}...\")\n",
        "print(f\"  Response: {TEST_RESPONSE[:80]}...\")\n",
        "print(f\"\\nNote: Using real AI model with environment variables loaded from backend/.env\\n\")\n",
        "\n",
        "eval_results = []\n",
        "\n",
        "for i in range(EVAL_NUM_RUNS):\n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"Completed {i + 1}/{EVAL_NUM_RUNS} evaluations...\")\n",
        "    \n",
        "    try:\n",
        "        result = EvalWrapper.evaluate(\n",
        "            environment_text=TEST_ENVIRONMENT,\n",
        "            user_response_text=TEST_RESPONSE,\n",
        "            service_type=\"custom\",\n",
        "            ai_model=EVAL_AI_MODEL,\n",
        "            verbose=False\n",
        "        )\n",
        "        \n",
        "        eval_results.append({\n",
        "            \"run\": i + 1,\n",
        "            \"success\": True,\n",
        "            \"result\": result\n",
        "        })\n",
        "    except Exception as e:\n",
        "        eval_results.append({\n",
        "            \"run\": i + 1,\n",
        "            \"success\": False,\n",
        "            \"error\": str(e),\n",
        "            \"error_type\": type(e).__name__\n",
        "        })\n",
        "        # Print first few errors for debugging\n",
        "        if i < 3:\n",
        "            print(f\"Error in run {i + 1}: {type(e).__name__}: {str(e)[:100]}\")\n",
        "\n",
        "print(f\"\\nEval Service Results:\")\n",
        "print(f\"  Successful: {sum(1 for r in eval_results if r['success'])}/{EVAL_NUM_RUNS}\")\n",
        "print(f\"  Failed: {sum(1 for r in eval_results if not r['success'])}/{EVAL_NUM_RUNS}\")\n",
        "\n",
        "if sum(1 for r in eval_results if not r['success']) > 0:\n",
        "    error_counts = Counter([r.get('error_type', 'Unknown') for r in eval_results if not r['success']])\n",
        "    print(f\"\\nError breakdown:\")\n",
        "    for error_type, count in error_counts.items():\n",
        "        print(f\"  {error_type}: {count}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "AI EVAL SERVICE - SCORE CONSISTENCY ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Overall Score Analysis:\n",
            "  Mean: 0.9000\n",
            "  Std Dev: 0.0000\n",
            "  Min: 0.9000\n",
            "  Max: 0.9000\n",
            "  Unique values: 1\n",
            "\n",
            "  Maximum Possible Score: 1.0000\n",
            "  Highest Score Achieved: 0.9000\n",
            "  Mean Score: 0.9000\n",
            "  % of Maximum (Mean): 90.00%\n",
            "  % of Maximum (Max): 90.00%\n",
            "  Distance from Max (Mean): 0.1000\n",
            "  Distance from Max (Best): 0.1000\n",
            "\n",
            "  ‚úÖ PERFECT CONSISTENCY: All scores are identical (0.9000)\n",
            "\n",
            "Individual Metrics Analysis:\n",
            "\n",
            "  appropriateness:\n",
            "    Mean: 1.0000\n",
            "    Std Dev: 0.0000\n",
            "    Max Achieved: 1.0000\n",
            "    Maximum Possible: 1.0000\n",
            "    % of Maximum (Mean): 100.00%\n",
            "    % of Maximum (Max): 100.00%\n",
            "    Unique values: 1\n",
            "    ‚úÖ Perfectly consistent\n",
            "\n",
            "  score:\n",
            "    Mean: 0.9000\n",
            "    Std Dev: 0.0000\n",
            "    Max Achieved: 0.9000\n",
            "    Maximum Possible: 1.0000\n",
            "    % of Maximum (Mean): 90.00%\n",
            "    % of Maximum (Max): 90.00%\n",
            "    Unique values: 1\n",
            "    ‚úÖ Perfectly consistent\n",
            "\n",
            "  completeness:\n",
            "    Mean: 0.8500\n",
            "    Std Dev: 0.0092\n",
            "    Max Achieved: 0.9000\n",
            "    Maximum Possible: 1.0000\n",
            "    % of Maximum (Mean): 85.00%\n",
            "    % of Maximum (Max): 90.00%\n",
            "    Unique values: 3\n",
            "    ‚úÖ Highly consistent\n",
            "\n",
            "  clarity:\n",
            "    Mean: 1.0000\n",
            "    Std Dev: 0.0000\n",
            "    Max Achieved: 1.0000\n",
            "    Maximum Possible: 1.0000\n",
            "    % of Maximum (Mean): 100.00%\n",
            "    % of Maximum (Max): 100.00%\n",
            "    Unique values: 1\n",
            "    ‚úÖ Perfectly consistent\n",
            "\n",
            "  action_validity:\n",
            "    Mean: 1.0000\n",
            "    Std Dev: 0.0000\n",
            "    Max Achieved: 1.0000\n",
            "    Maximum Possible: 1.0000\n",
            "    % of Maximum (Mean): 100.00%\n",
            "    % of Maximum (Max): 100.00%\n",
            "    Unique values: 1\n",
            "    ‚úÖ Perfectly consistent\n",
            "\n",
            "  creativity:\n",
            "    Mean: 0.5083\n",
            "    Std Dev: 0.0334\n",
            "    Max Achieved: 0.7000\n",
            "    Maximum Possible: 1.0000\n",
            "    % of Maximum (Mean): 50.83%\n",
            "    % of Maximum (Max): 70.00%\n",
            "    Unique values: 3\n",
            "    ‚ö†Ô∏è  Moderate variance\n",
            "\n",
            "Reasoning Consistency:\n",
            "  Unique reasonings: 59/60\n",
            "  ‚ö†Ô∏è  Reasoning varies significantly across runs\n"
          ]
        }
      ],
      "source": [
        "# Analyze AI Eval Service Results\n",
        "successful_eval = [r for r in eval_results if r['success']]\n",
        "\n",
        "if len(successful_eval) > 0:\n",
        "    scores = [r['result'].get('score', 0) for r in successful_eval]\n",
        "    \n",
        "    # Extract all metric keys from custom eval (different structure than mock)\n",
        "    all_metrics = {}\n",
        "    metric_keys = set()\n",
        "    for r in successful_eval:\n",
        "        # Custom eval returns: score, appropriateness, completeness, clarity, creativity, action_validity\n",
        "        for key in ['score', 'appropriateness', 'completeness', 'clarity', 'creativity', 'action_validity']:\n",
        "            if key in r['result']:\n",
        "                metric_keys.add(key)\n",
        "    \n",
        "    for key in metric_keys:\n",
        "        all_metrics[key] = [r['result'].get(key, 0) for r in successful_eval]\n",
        "    \n",
        "    print(\"=\" * 60)\n",
        "    print(\"AI EVAL SERVICE - SCORE CONSISTENCY ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    MAX_SCORE = 1.0  # Theoretical maximum score\n",
        "    \n",
        "    print(f\"\\nOverall Score Analysis:\")\n",
        "    print(f\"  Mean: {statistics.mean(scores):.4f}\")\n",
        "    print(f\"  Std Dev: {statistics.stdev(scores) if len(scores) > 1 else 0:.4f}\")\n",
        "    print(f\"  Min: {min(scores):.4f}\")\n",
        "    print(f\"  Max: {max(scores):.4f}\")\n",
        "    print(f\"  Unique values: {len(set(scores))}\")\n",
        "    print(f\"\\n  Maximum Possible Score: {MAX_SCORE:.4f}\")\n",
        "    print(f\"  Highest Score Achieved: {max(scores):.4f}\")\n",
        "    print(f\"  Mean Score: {statistics.mean(scores):.4f}\")\n",
        "    print(f\"  % of Maximum (Mean): {(statistics.mean(scores) / MAX_SCORE * 100):.2f}%\")\n",
        "    print(f\"  % of Maximum (Max): {(max(scores) / MAX_SCORE * 100):.2f}%\")\n",
        "    print(f\"  Distance from Max (Mean): {MAX_SCORE - statistics.mean(scores):.4f}\")\n",
        "    print(f\"  Distance from Max (Best): {MAX_SCORE - max(scores):.4f}\")\n",
        "    \n",
        "    if len(set(scores)) == 1:\n",
        "        print(f\"\\n  ‚úÖ PERFECT CONSISTENCY: All scores are identical ({scores[0]:.4f})\")\n",
        "    else:\n",
        "        score_variance = statistics.stdev(scores) if len(scores) > 1 else 0\n",
        "        if score_variance < 0.01:\n",
        "            print(f\"\\n  ‚úÖ HIGH CONSISTENCY: Very low variance ({score_variance:.4f})\")\n",
        "        elif score_variance < 0.05:\n",
        "            print(f\"\\n  ‚ö†Ô∏è  MODERATE CONSISTENCY: Some variance ({score_variance:.4f})\")\n",
        "        else:\n",
        "            print(f\"\\n  ‚ùå LOW CONSISTENCY: High variance ({score_variance:.4f})\")\n",
        "    \n",
        "    # Analyze individual metrics\n",
        "    print(f\"\\nIndividual Metrics Analysis:\")\n",
        "    for metric_name, values in all_metrics.items():\n",
        "        unique_count = len(set(values))\n",
        "        mean_val = statistics.mean(values)\n",
        "        std_val = statistics.stdev(values) if len(values) > 1 else 0\n",
        "        max_val = max(values)\n",
        "        MAX_METRIC = 1.0  # All metrics are 0-1 scale\n",
        "        \n",
        "        print(f\"\\n  {metric_name}:\")\n",
        "        print(f\"    Mean: {mean_val:.4f}\")\n",
        "        print(f\"    Std Dev: {std_val:.4f}\")\n",
        "        print(f\"    Max Achieved: {max_val:.4f}\")\n",
        "        print(f\"    Maximum Possible: {MAX_METRIC:.4f}\")\n",
        "        print(f\"    % of Maximum (Mean): {(mean_val / MAX_METRIC * 100):.2f}%\")\n",
        "        print(f\"    % of Maximum (Max): {(max_val / MAX_METRIC * 100):.2f}%\")\n",
        "        print(f\"    Unique values: {unique_count}\")\n",
        "        if unique_count == 1:\n",
        "            print(f\"    ‚úÖ Perfectly consistent\")\n",
        "        elif std_val < 0.01:\n",
        "            print(f\"    ‚úÖ Highly consistent\")\n",
        "        elif std_val < 0.05:\n",
        "            print(f\"    ‚ö†Ô∏è  Moderate variance\")\n",
        "        else:\n",
        "            print(f\"    ‚ùå High variance\")\n",
        "    \n",
        "    # Check reasoning consistency\n",
        "    reasonings = [r['result'].get('reasoning', '') for r in successful_eval]\n",
        "    unique_reasonings = len(set(reasonings))\n",
        "    print(f\"\\nReasoning Consistency:\")\n",
        "    print(f\"  Unique reasonings: {unique_reasonings}/{len(reasonings)}\")\n",
        "    if unique_reasonings == 1:\n",
        "        print(f\"  ‚úÖ Perfectly consistent reasoning\")\n",
        "    elif unique_reasonings < len(reasonings) * 0.1:\n",
        "        print(f\"  ‚úÖ Mostly consistent reasoning (few unique variants)\")\n",
        "    else:\n",
        "        print(f\"  ‚ö†Ô∏è  Reasoning varies significantly across runs\")\n",
        "else:\n",
        "    print(\"No successful evaluations to analyze!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "ADDITIONAL ANALYSIS\n",
            "============================================================\n",
            "\n",
            "Score Distribution:\n",
            "  Most common scores:\n",
            "    0.90: 60 times (100.0%)\n",
            "\n",
            "Score Range Distribution:\n",
            "  0.9-1.0 (Excellent): 60 (100.0%)\n",
            "  0.8-0.9 (Very Good): 0 (0.0%)\n",
            "  0.7-0.8 (Good): 0 (0.0%)\n",
            "  0.6-0.7 (Fair): 0 (0.0%)\n",
            "  0.0-0.6 (Poor): 0 (0.0%)\n",
            "\n",
            "Variance Analysis:\n",
            "  Coefficient of Variation: 0.00%\n",
            "    ‚úÖ Very low relative variance - highly consistent\n"
          ]
        }
      ],
      "source": [
        "# Additional Analysis: Score Distribution and Patterns\n",
        "if len(successful_eval) > 0:\n",
        "    # Get scores from successful evaluations\n",
        "    scores = [r['result'].get('score', 0) for r in successful_eval]\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ADDITIONAL ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Score distribution\n",
        "    print(f\"\\nScore Distribution:\")\n",
        "    score_counts = Counter([round(s, 2) for s in scores])\n",
        "    print(f\"  Most common scores:\")\n",
        "    for score_val, count in score_counts.most_common(10):\n",
        "        percentage = (count / len(scores)) * 100\n",
        "        print(f\"    {score_val:.2f}: {count} times ({percentage:.1f}%)\")\n",
        "    \n",
        "    # Check if scores cluster around certain values\n",
        "    score_ranges = {\n",
        "        \"0.9-1.0 (Excellent)\": sum(1 for s in scores if 0.9 <= s <= 1.0),\n",
        "        \"0.8-0.9 (Very Good)\": sum(1 for s in scores if 0.8 <= s < 0.9),\n",
        "        \"0.7-0.8 (Good)\": sum(1 for s in scores if 0.7 <= s < 0.8),\n",
        "        \"0.6-0.7 (Fair)\": sum(1 for s in scores if 0.6 <= s < 0.7),\n",
        "        \"0.0-0.6 (Poor)\": sum(1 for s in scores if 0.0 <= s < 0.6),\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nScore Range Distribution:\")\n",
        "    for range_name, count in score_ranges.items():\n",
        "        percentage = (count / len(scores)) * 100\n",
        "        print(f\"  {range_name}: {count} ({percentage:.1f}%)\")\n",
        "    \n",
        "    # Check for any patterns in variance\n",
        "    if len(scores) > 1:\n",
        "        score_variance = statistics.stdev(scores)\n",
        "        coefficient_of_variation = (score_variance / statistics.mean(scores)) * 100 if statistics.mean(scores) > 0 else 0\n",
        "        \n",
        "        print(f\"\\nVariance Analysis:\")\n",
        "        print(f\"  Coefficient of Variation: {coefficient_of_variation:.2f}%\")\n",
        "        if coefficient_of_variation < 5:\n",
        "            print(f\"    ‚úÖ Very low relative variance - highly consistent\")\n",
        "        elif coefficient_of_variation < 10:\n",
        "            print(f\"    ‚ö†Ô∏è  Low relative variance - generally consistent\")\n",
        "        elif coefficient_of_variation < 20:\n",
        "            print(f\"    ‚ö†Ô∏è  Moderate relative variance - some inconsistency\")\n",
        "        else:\n",
        "            print(f\"    ‚ùå High relative variance - significant inconsistency\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# This cell is intentionally left empty\n",
        "# All analysis is done in cells 14, 15, and 17\n",
        "pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "AI EVAL SERVICE - FINAL SUMMARY\n",
            "============================================================\n",
            "\n",
            "Overall Performance:\n",
            "  Mean Score: 0.9000\n",
            "  Max Score: 0.9000\n",
            "  Min Score: 0.9000\n",
            "  Score Range: 0.0000\n",
            "  Std Deviation: 0.0000\n",
            "\n",
            "Maximum Achievement:\n",
            "  Maximum Possible Score: 1.0000\n",
            "  Highest Score Achieved: 0.9000\n",
            "  Mean Score: 0.9000\n",
            "  % of Maximum (Mean): 90.00%\n",
            "  % of Maximum (Max): 90.00%\n",
            "  Distance from Max (Mean): 0.1000\n",
            "  Distance from Max (Best): 0.1000\n",
            "\n",
            "Consistency Assessment:\n",
            "  ‚úÖ PERFECT CONSISTENCY: All scores are identical\n",
            "\n",
            "Recommendations:\n",
            "  ‚úÖ The AI eval service is sufficiently consistent for production use\n",
            "  ‚úÖ Scores are close to maximum - evaluator is performing well\n"
          ]
        }
      ],
      "source": [
        "# Final Summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"AI EVAL SERVICE - FINAL SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if len(successful_eval) > 0:\n",
        "    MAX_SCORE = 1.0\n",
        "    eval_scores = [r['result'].get('score', 0) for r in successful_eval]\n",
        "    \n",
        "    eval_std = statistics.stdev(eval_scores) if len(eval_scores) > 1 else 0\n",
        "    eval_mean = statistics.mean(eval_scores)\n",
        "    eval_max = max(eval_scores)\n",
        "    eval_min = min(eval_scores)\n",
        "    \n",
        "    print(f\"\\nOverall Performance:\")\n",
        "    print(f\"  Mean Score: {eval_mean:.4f}\")\n",
        "    print(f\"  Max Score: {eval_max:.4f}\")\n",
        "    print(f\"  Min Score: {eval_min:.4f}\")\n",
        "    print(f\"  Score Range: {eval_max - eval_min:.4f}\")\n",
        "    print(f\"  Std Deviation: {eval_std:.4f}\")\n",
        "    \n",
        "    print(f\"\\nMaximum Achievement:\")\n",
        "    print(f\"  Maximum Possible Score: {MAX_SCORE:.4f}\")\n",
        "    print(f\"  Highest Score Achieved: {eval_max:.4f}\")\n",
        "    print(f\"  Mean Score: {eval_mean:.4f}\")\n",
        "    print(f\"  % of Maximum (Mean): {(eval_mean / MAX_SCORE * 100):.2f}%\")\n",
        "    print(f\"  % of Maximum (Max): {(eval_max / MAX_SCORE * 100):.2f}%\")\n",
        "    print(f\"  Distance from Max (Mean): {MAX_SCORE - eval_mean:.4f}\")\n",
        "    print(f\"  Distance from Max (Best): {MAX_SCORE - eval_max:.4f}\")\n",
        "    \n",
        "    print(f\"\\nConsistency Assessment:\")\n",
        "    if eval_std == 0:\n",
        "        print(f\"  ‚úÖ PERFECT CONSISTENCY: All scores are identical\")\n",
        "    elif eval_std < 0.01:\n",
        "        print(f\"  ‚úÖ EXCELLENT CONSISTENCY: Very low variance ({eval_std:.4f})\")\n",
        "        print(f\"     AI evaluator is highly consistent for same inputs\")\n",
        "    elif eval_std < 0.05:\n",
        "        print(f\"  ‚ö†Ô∏è  MODERATE CONSISTENCY: Some variance ({eval_std:.4f})\")\n",
        "        print(f\"     AI evaluator shows some variation but generally consistent\")\n",
        "    elif eval_std < 0.1:\n",
        "        print(f\"  ‚ö†Ô∏è  MODERATE VARIANCE: Noticeable variance ({eval_std:.4f})\")\n",
        "        print(f\"     AI evaluator shows moderate variation\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå HIGH VARIANCE: Significant variance ({eval_std:.4f})\")\n",
        "        print(f\"     AI evaluator shows high inconsistency for same inputs\")\n",
        "    \n",
        "    print(f\"\\nRecommendations:\")\n",
        "    if eval_std < 0.05:\n",
        "        print(f\"  ‚úÖ The AI eval service is sufficiently consistent for production use\")\n",
        "        if eval_max >= 0.9:\n",
        "            print(f\"  ‚úÖ Scores are close to maximum - evaluator is performing well\")\n",
        "        elif eval_max >= 0.7:\n",
        "            print(f\"  ‚ö†Ô∏è  Scores are moderate - evaluator may be conservative\")\n",
        "        else:\n",
        "            print(f\"  ‚ö†Ô∏è  Scores are low - evaluator may be too strict or response needs improvement\")\n",
        "    elif eval_std < 0.1:\n",
        "        print(f\"  ‚ö†Ô∏è  The eval service shows some variance - consider averaging multiple evaluations\")\n",
        "        print(f\"     This will help reduce variance and provide more reliable scores\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå The eval service shows high variance - same inputs produce different scores\")\n",
        "        print(f\"     Consider:\")\n",
        "        print(f\"     - Using temperature=0 for more deterministic outputs\")\n",
        "        print(f\"     - Averaging multiple evaluation runs\")\n",
        "        print(f\"     - Using a more deterministic evaluation approach\")\n",
        "else:\n",
        "    print(\"\\n‚ùå No successful evaluations to analyze!\")\n",
        "    if eval_results:\n",
        "        print(\"\\nErrors encountered:\")\n",
        "        error_counts = Counter([r.get('error_type', 'Unknown') for r in eval_results if not r['success']])\n",
        "        for error_type, count in error_counts.most_common(5):\n",
        "            print(f\"  {error_type}: {count} times\")\n",
        "        print(\"\\nFirst few error messages:\")\n",
        "        for i, result in enumerate([r for r in eval_results if not r['success']][:3]):\n",
        "            print(f\"  Run {result['run']}: {result.get('error', 'Unknown')[:100]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ All runs completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Check for any errors in failed runs\n",
        "failed_runs = [r for r in all_results if not r['success']]\n",
        "if failed_runs:\n",
        "    print(f\"\\nFailed Runs ({len(failed_runs)}):\")\n",
        "    for failed in failed_runs[:5]:  # Show first 5 failures\n",
        "        print(f\"  Run {failed['run_number']}: {failed.get('error', 'Unknown error')}\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ All runs completed successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
